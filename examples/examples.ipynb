{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS Music: Mass Spectrometry Data Sonification\n",
    "\n",
    "This notebook demonstrates the capabilities of the `ms_music` Python package, which allows users to convert mass spectrometry data from `.mzML` files into audio.\n",
    "\n",
    "**Note:** This notebook assumes you have already installed the `ms_music` package and its dependencies (numpy, pandas, matchms, wavio, librosa, scipy, tqdm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f80d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "import os\n",
    "\n",
    "# Assuming your package is named 'ms_music' and is importable\n",
    "try:\n",
    "    from ms_music import MSSonifier\n",
    "    from ms_music import effects as ms_effects # Not strictly needed if calling via sonifier.apply_effect\n",
    "except ImportError:\n",
    "    print(\"MSSonifier class not found. Make sure the 'ms_music' package is installed and named correctly.\")\n",
    "    print(\"If you are running this from the source directory without installation, ensure paths are correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b00521",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "You'll need an `.mzML` file to run this demonstration. \n",
    "\n",
    "**Action Required:**\n",
    "1. Create a folder named `sample_data` in the same directory as this notebook.\n",
    "2. Place your `.mzML` file into the `sample_data` folder.\n",
    "3. Update the `mzml_filename` variable below with the name of your file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ea440",
   "metadata": {},
   "outputs": [],
   "source": [
    "mzml_filename = \".mzML\"  # Replace with your actual mzML file name\n",
    "sample_data_dir = \"sample_data_dir\"\n",
    "output_audio_dir = \"output_audio_dir\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(sample_data_dir, exist_ok=True)\n",
    "os.makedirs(output_audio_dir, exist_ok=True)\n",
    "\n",
    "mzml_filepath = os.path.join(sample_data_dir, mzml_filename)\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(mzml_filepath):\n",
    "    print(f\"ERROR: mzML file not found at {mzml_filepath}\")\n",
    "    print(\"Please place your mzML file in the 'sample_data' directory and update 'mzml_filename'.\")\n",
    "else:\n",
    "    print(f\"Using mzML file: {mzml_filepath}\")\n",
    "\n",
    "# Sonification parameters\n",
    "MS_LEVEL = 1                # MS level to process (1 or 2)\n",
    "TOTAL_DURATION_MIN = 2   # Desired output audio duration in minutes (keep it very short for demos)\n",
    "SAMPLE_RATE = 44100         # Audio sample rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c0c753",
   "metadata": {},
   "source": [
    "## 3. Initialize the Sonifier and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonifier = None # Initialize sonifier to None\n",
    "if os.path.exists(mzml_filepath):\n",
    "    sonifier = MSSonifier(\n",
    "        filepath=mzml_filepath,\n",
    "        ms_level=MS_LEVEL,\n",
    "        total_duration_minutes=TOTAL_DURATION_MIN,\n",
    "        sample_rate=SAMPLE_RATE\n",
    "    )\n",
    "    sonifier.load_and_preprocess_data()\n",
    "else:\n",
    "    print(\"Skipping sonifier initialization as mzML file is not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a826568",
   "metadata": {},
   "source": [
    "## 4. Generate Base Audio for Effects Demonstration\n",
    "\n",
    "We'll generate one or two base audio files using different sonification methods. These will then be used as input for showcasing the effects. We'll primarily use the ADSR output for effects demonstration as it often provides a clearer canvas for hearing effect changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cde008",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_gradient_audio = None\n",
    "\n",
    "if sonifier and sonifier.processed_spectra_dfs is not None:\n",
    "    print(\"\\n--- Generating Base Gradient Audio ---\")\n",
    "    sonifier.sonify(method='gradient', method_params={'overlap_percentage': 0.05})\n",
    "    base_gradient_audio = sonifier.get_current_audio()\n",
    "    if base_gradient_audio is not None and base_gradient_audio.size > 0:\n",
    "        # Normalize base_gradient_audio so that it's amplitude is between -1 and 1\n",
    "        if base_gradient_audio is not None:\n",
    "            max_amplitude = np.max(np.abs(base_gradient_audio))\n",
    "            if max_amplitude > 0:\n",
    "                base_gradient_audio /= max_amplitude\n",
    "                print(\"Base gradient audio normalized.\")\n",
    "        output_base_gradient_path = os.path.join(output_audio_dir, \"base_audio_gradient.wav\")\n",
    "        sonifier.save_audio(output_base_gradient_path)\n",
    "        print(f\"Base Gradient audio saved to {output_base_gradient_path}\")\n",
    "        display(Audio(data=base_gradient_audio, rate=SAMPLE_RATE, normalize=True))\n",
    "    else:\n",
    "        print(\"Base Gradient sonification did not produce audio.\")\n",
    "else:\n",
    "    print(\"Sonifier not ready. Cannot generate base audio.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07db98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_adsr_audio = None\n",
    "\n",
    "if sonifier and sonifier.processed_spectra_dfs is not None:\n",
    "    print(\"\\n--- Generating Base ADSR Audio ---\")\n",
    "    adsr_settings = {\n",
    "        'attack_time_pc': 0.02, 'decay_time_pc': 0.05,\n",
    "        'sustain_level_pc': 0.7, 'release_time_pc': 0.1,\n",
    "        'randomize': False\n",
    "    }\n",
    "    sonifier.sonify(method='adsr', method_params={'adsr_settings': adsr_settings})\n",
    "    base_adsr_audio = sonifier.get_current_audio()\n",
    "    if base_adsr_audio is not None and base_adsr_audio.size > 0:\n",
    "        output_base_adsr_path = os.path.join(output_audio_dir, \"base_audio_adsr.wav\")\n",
    "        sonifier.save_audio(output_base_adsr_path)\n",
    "        print(f\"Base ADSR audio saved to {output_base_adsr_path}\")\n",
    "        display(Audio(data=base_adsr_audio, rate=SAMPLE_RATE, normalize=True))\n",
    "    else:\n",
    "        print(\"Base ADSR sonification did not produce audio.\")\n",
    "else:\n",
    "    print(\"Sonifier not ready. Cannot generate base audio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effffc42",
   "metadata": {},
   "source": [
    "## 5. Applying Audio Effects\n",
    "\n",
    "Now, we'll demonstrate various audio effects. For each effect, we will reload the `base_adsr_audio` into the sonifier's current buffer to ensure we're applying the effect to a consistent input, making it easier to discern the impact of each individual effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc35091a",
   "metadata": {},
   "source": [
    "### 5.1. Standard Audio Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51c43bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to reset sonifier's audio and apply/save/display an effect\n",
    "def demonstrate_effect(effect_name, effect_params, base_audio, filename_suffix):\n",
    "    if sonifier is None or base_audio is None or base_audio.size == 0:\n",
    "        print(f\"Skipping effect '{effect_name}': Sonifier or base audio not ready.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n--- Demonstrating Effect: {effect_name} ---\")\n",
    "    sonifier.current_audio_data = np.copy(base_audio) # Reset to base audio\n",
    "    \n",
    "    sonifier.apply_effect(effect_name, effect_params=effect_params)\n",
    "    effect_output_audio = sonifier.get_current_audio()\n",
    "    \n",
    "    if effect_output_audio is not None and effect_output_audio.size > 0:\n",
    "        output_path = os.path.join(output_audio_dir, f\"effect_{filename_suffix}.wav\")\n",
    "        sonifier.save_audio(output_path)\n",
    "        print(f\"{effect_name} audio saved to {output_path}\")\n",
    "        display(Audio(data=effect_output_audio, rate=SAMPLE_RATE, normalize=False))\n",
    "    else:\n",
    "        print(f\"{effect_name} did not produce audio or an error occurred.\")\n",
    "\n",
    "# Ensure base_gradient_audio is available for the following demonstrations\n",
    "if 'base_gradient_audio' not in locals() or base_gradient_audio is None:\n",
    "    print(\"Base ADSR audio is not available. Effects demonstration will be skipped.\")\n",
    "else:\n",
    "    # HPSS (Harmonic)\n",
    "    demonstrate_effect('hpss', \n",
    "                       {'margin': 16, 'harmonic': True, 'percussive': False}, \n",
    "                       base_gradient_audio, \n",
    "                       'hpss_harmonic')\n",
    "\n",
    "    # HPSS (Percussive)\n",
    "    demonstrate_effect('hpss', \n",
    "                       {'margin': 16, 'harmonic': False, 'percussive': True}, \n",
    "                       base_gradient_audio, \n",
    "                       'hpss_percussive')\n",
    "\n",
    "    # Notch Filter\n",
    "    demonstrate_effect('notch_filter', \n",
    "                       {'notch_freq': 1000, 'quality_factor': 10}, \n",
    "                       base_gradient_audio, \n",
    "                       'notch_filter_1kHz')\n",
    "\n",
    "    # Butterworth Low-pass Filter\n",
    "    demonstrate_effect('butterworth_filter', \n",
    "                       {'cutoff_freq': 800, 'btype': 'low', 'order': 4}, \n",
    "                       base_gradient_audio, \n",
    "                       'butterworth_lowpass_800Hz')\n",
    "\n",
    "    # Butterworth Band-pass Filter\n",
    "    demonstrate_effect('butterworth_filter', \n",
    "                       {'cutoff_freq': (300, 1200), 'btype': 'bandpass', 'order': 3, 'gustafson_method': True}, \n",
    "                       base_gradient_audio, \n",
    "                       'butterworth_bandpass_300_1200Hz')\n",
    "\n",
    "    # Chebyshev Type I Low-pass Filter\n",
    "    demonstrate_effect('chebyshev1_filter', \n",
    "                       {'cutoff_freq': 1500, 'ripple_db': 1, 'btype': 'low', 'order': 4}, \n",
    "                       base_gradient_audio, \n",
    "                       'chebyshev1_lowpass_1500Hz_1dB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395fdf61",
   "metadata": {},
   "source": [
    "### 5.2. Experimental Audio Effects\n",
    "\n",
    "These effects are derived from the user's original `complex.py` script and are marked as experimental. They might be unstable, produce unexpected results, or be computationally intensive. Use with caution and for exploratory purposes. Some might effectively be no-ops if their internal logic was flagged as non-functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc3413",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'base_gradient_audio' not in locals() or base_gradient_audio is None:\n",
    "    print(\"Base ADSR audio is not available. Experimental effects demonstration will be skipped.\")\n",
    "else:\n",
    "    # Experimental PLL Filter (likely a no-op returning original audio)\n",
    "    demonstrate_effect('experimental_pll_filter', \n",
    "                       {'loop_gain': 0.01, 'loop_bandwidth': 50.0, 'center_freq': 500.0, 'freq_deviation': 20.0}, \n",
    "                       base_gradient_audio, \n",
    "                       'exp_pll_filter')\n",
    "\n",
    "    # Experimental LMS Modulation\n",
    "    demonstrate_effect('experimental_lms_modulation', \n",
    "                       {'n_segments': 50, 'mu': 0.02}, # Reduced n_segments for faster demo\n",
    "                       base_gradient_audio, \n",
    "                       'exp_lms_modulation')\n",
    "\n",
    "    # Experimental Spectral Analysis FM\n",
    "    demonstrate_effect('experimental_spectral_analysis_fm', \n",
    "                       {}, # No specific params other than audio_data and sample_rate\n",
    "                       base_gradient_audio, \n",
    "                       'exp_spectral_analysis_fm')\n",
    "\n",
    "    # Experimental Phase Vocoder Modulation (placeholder implementation)\n",
    "    demonstrate_effect('experimental_phase_vocoder_modulation', \n",
    "                       {'n_fft': 2048, 'hop_length': 512}, \n",
    "                       base_gradient_audio, \n",
    "                       'exp_phase_vocoder_mod')\n",
    "\n",
    "    # Experimental FFT Filter\n",
    "    demonstrate_effect('experimental_fft_filter', \n",
    "                       {'threshold_abs_coeff': 2.0}, \n",
    "                       base_gradient_audio, \n",
    "                       'exp_fft_filter_thresh2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7a8e33",
   "metadata": {},
   "source": [
    "## 6. Visualizing Spectrograms\n",
    "\n",
    "You can use `librosa.display` to visualize the spectrogram of the generated audio. We'll plot the base ADSR audio and one of the processed outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be4c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(audio_data, sr, title=\"Spectrogram\"):\n",
    "    if audio_data is None or audio_data.size == 0:\n",
    "        print(f\"Cannot plot spectrogram for {title}: No audio data.\")\n",
    "        return\n",
    "    # Ensure audio is float for STFT\n",
    "    audio_float = audio_data.astype(np.float32)\n",
    "    # Normalize if it's int16 from saving/loading without explicit normalization for display\n",
    "    if np.issubdtype(audio_float.dtype, np.integer):\n",
    "        audio_float = audio_float / (2**15 -1) # Basic normalization for int16\n",
    "        \n",
    "    X = librosa.stft(audio_float)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log') # Using log y-axis\n",
    "    plt.title(title)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.show()\n",
    "\n",
    "if 'base_gradient_audio' in locals() and base_gradient_audio is not None:\n",
    "    plot_spectrogram(base_gradient_audio, SAMPLE_RATE, \"Spectrogram of Base gradient Audio\")\n",
    "\n",
    "# Example: Plot spectrogram of the Butterworth low-pass filtered audio\n",
    "if sonifier and os.path.exists(os.path.join(output_audio_dir, 'effect_butterworth_lowpass_800Hz.wav')):\n",
    "    # Load the saved audio to ensure we plot what was displayed\n",
    "    try:\n",
    "        butterworth_audio_loaded, sr_loaded = librosa.load(os.path.join(output_audio_dir, 'effect_butterworth_lowpass_800Hz.wav'), sr=SAMPLE_RATE)\n",
    "        plot_spectrogram(butterworth_audio_loaded, SAMPLE_RATE, \"Spectrogram of Butterworth Low-Pass Filtered ADSR Audio\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load or plot spectrogram for Butterworth filtered audio: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701df2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
